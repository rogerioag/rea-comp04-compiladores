{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-comp-analise-sintatica-cmmparser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerioag/rea-comp04-compiladores/blob/main/jupyter-notebooks/02-comp-analise-sintatica-cmmparser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQtiaYOH3xV9"
      },
      "source": [
        "# Análise Sintática\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeeNLwAv9P-4"
      },
      "source": [
        "# Introdução\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiSsFqEh9VY5"
      },
      "source": [
        "# Preparação do Ambiente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9TX9STdBDfD",
        "outputId": "96182720-1cac-47a1-f19c-156ce722dd9e"
      },
      "source": [
        "!pip install ply\n",
        "!pip install anytree\n",
        "!pip install graphviz\n",
        "!pip install llvmlite\n",
        "!jupyter nbextension install https://rawgit.com/jfbercher/small_nbextensions/master/highlighter.zip  --user\n",
        "!jupyter nbextension enable highlighter/highlighter"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ply in /usr/local/lib/python3.7/dist-packages (3.11)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Downloading: https://rawgit.com/jfbercher/small_nbextensions/master/highlighter.zip -> /tmp/tmpys_gg4/highlighter.zip\n",
            "Extracting: /tmp/tmpys_gg4/highlighter.zip -> /root/.local/share/jupyter/nbextensions\n",
            "Enabling notebook extension highlighter/highlighter...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5zbHzlP92i7"
      },
      "source": [
        "# Copiando Módulos do Projeto\n",
        "\n",
        "Aqui iremos copiar o projeto `rea-comp04-compiladores` do repositório do [`github`](https://github.com/rogerioag/rea-comp04-compiladores):\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/rogerioag/rea-comp04-compiladores.git\n",
        "```\n",
        "Iremos copiar os módulos e os arquivos de testes para o diretório de conteúdo do _notebook_, o __content__.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3CciW1-tIp1",
        "outputId": "85d96dae-81b8-42ab-8aff-101acdaf9608"
      },
      "source": [
        "! rm -rf rea-comp04-compiladores\n",
        "! git clone https://github.com/rogerioag/rea-comp04-compiladores.git\n",
        "! cp -R rea-comp04-compiladores/cmmcompiler/* .\n",
        "! cp -R rea-comp04-compiladores/cmmcompiler/tests/* .\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rea-comp04-compiladores'...\n",
            "remote: Enumerating objects: 470, done.\u001b[K\n",
            "remote: Counting objects: 100% (470/470), done.\u001b[K\n",
            "remote: Compressing objects: 100% (370/370), done.\u001b[K\n",
            "remote: Total 470 (delta 264), reused 234 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (470/470), 2.87 MiB | 2.55 MiB/s, done.\n",
            "Resolving deltas: 100% (264/264), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1X7BKd1lF0A"
      },
      "source": [
        "import ply.yacc as yacc\n",
        "from lexer import tokens\n",
        "import re as regex\n",
        "\n",
        "from sys import argv, exit\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "     level = logging.DEBUG,\n",
        "     filename = \"cmmcompiler.log\",\n",
        "     filemode = \"w\",\n",
        "     format = \"%(filename)10s:%(lineno)4d:%(message)s\"\n",
        ")\n",
        "log = logging.getLogger()\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L72TwQGp-LLa"
      },
      "source": [
        "O conjunto de regras do `parser` está organizado em múltiplos arquivos e as inicializações e importações são feitas no arquivo `parser/grammar/__init__.py`.\n",
        "\n",
        "Os aquivos com as regras são importados na sequência:\n",
        "```python\n",
        "from .declarations import *\n",
        "from .expressions import *\n",
        "from .operations import *\n",
        "from .params import *\n",
        "from .types import *\n",
        "from .statements import *\n",
        "```\n",
        "\n",
        "Aqui vamos incluir os conteúdos de cada um dos arquivos. O conteúdo de `parser/grammar/declarations.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_rJYh575BMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7464a2-5dac-4250-92bc-209c3e55487f"
      },
      "source": [
        "%%writefile parser/grammar/declarations.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "def p_declaration_list(parser):\n",
        "    \"\"\"declaration-list : declaration-list declaration\n",
        "                        | declaration\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='declaration-list')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "        [dec] = parser[2:3]\n",
        "        node.insert_node(dec)\n",
        "        pass\n",
        "    else:\n",
        "        node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_declaration(parser):\n",
        "    \"\"\"declaration : var-declaration\n",
        "                   | fun-declaration\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='declaration')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_var_declaration(parser):\n",
        "    \"\"\"var-declaration : type-specifier id SEMICOLON\n",
        "                       | type-specifier id LBRACKETS number RBRACKETS SEMICOLON\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='var-declaration')\n",
        "\n",
        "    [node, type_spec, id_node, symbol] = parser[:4]\n",
        "\n",
        "    node.insert_node(type_spec)\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == symbol:\n",
        "        node.insert_node_with_child(TreeNode(id='SEMICOLON'), TreeNode(raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "        pass\n",
        "    elif TOKENS_SYMBOLS.get('LBRACKETS') == symbol:\n",
        "        node.insert_node_with_child(TreeNode(id='LBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "\n",
        "        [number] = parser[4:5]\n",
        "        node.insert_node(number)\n",
        "\n",
        "        node.insert_node_with_child(TreeNode(id='RBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "\n",
        "        node.insert_node_with_child(TreeNode(id='SEMICOLON'), TreeNode(raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_fun_declaration(parser):\n",
        "    \"\"\"fun-declaration : type-specifier id LPAREN params RPAREN compound-stmt\"\"\"\n",
        "    parser[0] = TreeNode(id='fun-declaration')\n",
        "\n",
        "    [node, type_spec, id_node, _, params, _, compound] = parser\n",
        "\n",
        "    node.insert_node(type_spec)\n",
        "    node.insert_node(id_node)\n",
        "    node.insert_node_with_child(TreeNode(id='LPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(params)\n",
        "    node.insert_node_with_child(TreeNode(id='RPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(compound)\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_local_declarations(parser):\n",
        "    \"\"\"local-declarations : local-declarations var-declaration\n",
        "                          | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='local-declarations')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [var] = parser[2:3]\n",
        "        node.insert_node(var)\n",
        "        pass\n",
        "    pass\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/declarations.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Pdph3ZjokY"
      },
      "source": [
        "Conteúdo de `parser/grammar/expressions.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP2-jB4f5EdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780c06a7-4800-4b35-d905-a14bc9b5dd20"
      },
      "source": [
        "%%writefile parser/grammar/expressions.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "def p_expressions(parser):\n",
        "    \"\"\"expression : var ATTRIBUTION expression\n",
        "                  | simple-expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='expression')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    if len(parser) > 2:\n",
        "        [_, exp] = parser[2:4]\n",
        "        attrib_sym = TreeNode(raw=TOKENS_SYMBOLS.get('ATTRIBUTION'))\n",
        "        attrib_node = TreeNode(id='ATTRIBUTION')\n",
        "        attrib_node.insert_node(attrib_sym)\n",
        "        node.insert_node(attrib_node)\n",
        "\n",
        "        node.insert_node(exp)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_simple(parser):\n",
        "    \"\"\"simple-expression : additive-expression relop additive-expression\n",
        "                         | additive-expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='simple-expression')\n",
        "\n",
        "    [node, add] = parser[:2]\n",
        "\n",
        "    node.insert_node(add)\n",
        "    if len(parser) > 2:\n",
        "        [relop, addi] = parser[2:4]\n",
        "        node.insert_node(relop)\n",
        "        node.insert_node(addi)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_additive(parser):\n",
        "    \"\"\"additive-expression : additive-expression addop term\n",
        "                           | term\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='additive-expression')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    if len(parser) > 2:\n",
        "        [addop, term] = parser[2:4]\n",
        "        node.insert_node(addop)\n",
        "        node.insert_node(term)\n",
        "        pass\n",
        "    pass\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/expressions.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSjkzYNVj3U9"
      },
      "source": [
        "Conteúdo de `parser/grammar/operations.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbuPEMzy5Gxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a05b67-ec8f-46a5-bfce-d799f00ba744"
      },
      "source": [
        "%%writefile parser/grammar/operations.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "def get_token_by_raw(raw):\n",
        "    \n",
        "    for (token, value) in TOKENS_SYMBOLS.items():\n",
        "        if value == raw:\n",
        "            return token\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "def p_relational(parser):\n",
        "    \"\"\"relop : LESS_EQUAL\n",
        "             | LESS\n",
        "             | GREATER\n",
        "             | GREATER_EQUAL\n",
        "             | EQUALS\n",
        "             | DIFFERENT\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw))\n",
        "    parser[0].insert_node(TreeNode(raw=raw))\n",
        "    pass\n",
        "\n",
        "def p_addition(parser):\n",
        "    \"\"\"addop : PLUS\n",
        "             | MINUS\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw))\n",
        "    parser[0].insert_node(TreeNode(raw=raw))\n",
        "    pass\n",
        "\n",
        "def p_multiplication(parser):\n",
        "    \"\"\"mulop : TIMES\n",
        "             | DIVIDE\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw))\n",
        "    parser[0].insert_node(TreeNode(raw=raw))\n",
        "    pass\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/operations.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV5WsSh9kQPA"
      },
      "source": [
        "Conteúdo de `parser/grammar/params.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEOieoD5Jao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d07800-6332-4812-9ff5-346f64c97861"
      },
      "source": [
        "%%writefile parser/grammar/params.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "import logging\n",
        "log = logging.getLogger()\n",
        "\n",
        "def p_params(parser):\n",
        "    \"\"\"params : param-list\n",
        "              | void\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='params')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_params_error(parser):\n",
        "    \"\"\"params : error\n",
        "    \"\"\"\n",
        "    print(\"Erro: 'param-list' ou 'void' esperado.\")\n",
        "    parser[0] = TreeNode(id='ERROR::{}'.format(parser.lineno(1)))\n",
        "\n",
        "    [node, subtree] = parser\n",
        "    node.insert_node(subtree)\n",
        "    \n",
        "    log.error(\"Syntax error parsing 'params' rule at line {}\".format(parser.lineno(1)))\n",
        "        \n",
        "    pass\n",
        "\n",
        "def p_param_list(parser):\n",
        "    \"\"\"param-list : param-list COMMA param\n",
        "                  | param\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='param-list')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "\n",
        "        [_, param] = parser[2:4]\n",
        "        node.insert_node_with_child(TreeNode(id='COMMA'), TreeNode(raw=TOKENS_SYMBOLS.get('COMMA')))\n",
        "        node.insert_node(param)\n",
        "    else:\n",
        "        node.insert_node(subtree)\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_param(parser):\n",
        "    \"\"\"param : type-specifier id\n",
        "             | type-specifier id LBRACKETS RBRACKETS\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='param')\n",
        "\n",
        "    [node, subtree, id_node] = parser[:3]\n",
        "    node.insert_node(subtree)\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "    if len(parser) > 3:\n",
        "        node.insert_node_with_child(TreeNode(id='LBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "        node.insert_node_with_child(TreeNode(id='RBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "        pass\n",
        "\n",
        "    pass"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/params.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDOiEsRgkhBD"
      },
      "source": [
        "Conteúdo de `parser/grammar/types.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aI_VH_25Ln8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e87cc8-cf36-43ef-e2d4-28566fbdf652"
      },
      "source": [
        "%%writefile parser/grammar/types.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "def p_type_specifier(parser):\n",
        "    \"\"\"type-specifier : int\n",
        "                      | void\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='type-specifier')\n",
        "    [node, type_node] = parser\n",
        "\n",
        "    node.insert_node(type_node)\n",
        "    pass\n",
        "\n",
        "def p_void(parser):\n",
        "    \"\"\"void : VOID \"\"\"\n",
        "    \n",
        "    parser[0] = TreeNode(id='VOID')\n",
        "    [node, lexeme] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=lexeme))\n",
        "    pass\n",
        "\n",
        "def p_int(parser):\n",
        "    \"\"\"int : INT \"\"\"\n",
        "    \n",
        "    parser[0] = TreeNode(id='INT')\n",
        "    [node, lexeme] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=lexeme))\n",
        "\n",
        "    pass"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/types.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iua7Lzaokp1X"
      },
      "source": [
        "Conteúdo de `parser/grammar/statements.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5PFMFeT5PCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426e9132-39cf-45a1-84d9-0f0aed957242"
      },
      "source": [
        "%%writefile parser/grammar/statements.py\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "def p_statement_list(parser):\n",
        "    \"\"\"statement-list : statement-list statement\n",
        "                      | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='statement-list')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "        [stmt] = parser[2:3]\n",
        "        node.insert_node(stmt)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_statement(parser):\n",
        "    \"\"\"statement : expression-stmt\n",
        "                 | compound-stmt\n",
        "                 | selection-stmt\n",
        "                 | iteration-stmt\n",
        "                 | return-stmt\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='statement')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_expression(parser):\n",
        "    \"\"\"expression-stmt : expression SEMICOLON\n",
        "                       | SEMICOLON\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='expression-stmt')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == leaf:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=leaf)\n",
        "\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_node_with_child(TreeNode(id='SEMICOLON'), TreeNode(raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_compound(parser):\n",
        "    \"\"\"compound-stmt : LBRACES local-declarations statement-list RBRACES\"\"\"\n",
        "\n",
        "    parser[0] = TreeNode(id='compound-stmt')\n",
        "\n",
        "    [node, _, local_decl, stmt_list, _] = parser\n",
        "\n",
        "    node.insert_node_with_child(TreeNode(id='LBRACES'), TreeNode(raw=TOKENS_SYMBOLS.get('LBRACES')))\n",
        "    node.insert_node(local_decl)\n",
        "    node.insert_node(stmt_list)\n",
        "    node.insert_node_with_child(TreeNode(id='RBRACES'), TreeNode(raw=TOKENS_SYMBOLS.get('RBRACES')))\n",
        "    \n",
        "    pass\n",
        "\n",
        "def p_selection(parser):\n",
        "    \"\"\"selection-stmt : IF LPAREN expression RPAREN statement\n",
        "                      | IF LPAREN expression RPAREN statement ELSE statement\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='selection-stmt')\n",
        "\n",
        "    [node, _, _, exp, _, stmt] = parser[:6]\n",
        "\n",
        "    node.insert_node_with_child(TreeNode(id='IF'), TreeNode(raw=TOKENS_SYMBOLS.get('IF')))\n",
        "    node.insert_node_with_child(TreeNode(id='LPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(exp)\n",
        "    node.insert_node_with_child(TreeNode(id='RPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(stmt)\n",
        "\n",
        "    if len(parser) > 6:\n",
        "        [_, stmt] = parser[6:8]\n",
        "        node.insert_node_with_child(TreeNode(id='ELSE'), TreeNode(raw=TOKENS_SYMBOLS.get('ELSE')))\n",
        "        node.insert_node(stmt)\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_iteration(parser):\n",
        "    \"\"\"iteration-stmt : WHILE LPAREN expression RPAREN statement\"\"\"\n",
        "    \n",
        "    parser[0] = TreeNode(id='iteration-stmt')\n",
        "\n",
        "    [node, _, _, exp, _, stmt] = parser\n",
        "\n",
        "    node.insert_node_with_child(TreeNode(id='WHILE'), TreeNode(raw=TOKENS_SYMBOLS.get('WHILE')))\n",
        "    node.insert_node_with_child(TreeNode(id='LPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(exp)\n",
        "    node.insert_node_with_child(TreeNode(id='RPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(stmt)\n",
        "    pass\n",
        "\n",
        "def p_return(parser):\n",
        "    \"\"\"return-stmt : RETURN SEMICOLON\n",
        "                   | RETURN expression SEMICOLON\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='return-stmt')\n",
        "\n",
        "    [node, _, leaf] = parser[:3]\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == leaf:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=leaf)\n",
        "\n",
        "    node.insert_node_with_child(TreeNode(id='RETURN'), TreeNode(raw=TOKENS_SYMBOLS.get('RETURN')))\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 3:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=TOKENS_SYMBOLS.get('SEMICOLON'))\n",
        "\n",
        "    pass\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/statements.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oujVEZNRk--1"
      },
      "source": [
        "Conteúdo final de `parser/grammar/__init__.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQgiplz5lF0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35b18eba-228c-4f07-ad83-5e8704fe348c"
      },
      "source": [
        "%%writefile parser/grammar/__init__.py\n",
        "\n",
        "import ply.yacc as yacc\n",
        "from lexer import tokens\n",
        "import re as regex\n",
        "\n",
        "from sys import argv, exit\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "     level = logging.DEBUG,\n",
        "     filename = \"cmmcompiler.log\",\n",
        "     filemode = \"w\",\n",
        "     format = \"%(filename)10s:%(lineno)4d:%(message)s\"\n",
        ")\n",
        "log = logging.getLogger()\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode\n",
        "\n",
        "from .declarations import *\n",
        "from .expressions import *\n",
        "from .operations import *\n",
        "from .params import *\n",
        "from .types import *\n",
        "from .statements import *\n",
        "\n",
        "def p_program(parser):\n",
        "    \"\"\"program : declaration-list\"\"\"\n",
        "\n",
        "    global syntax_tree\n",
        "\n",
        "    parser[0] = TreeNode(id='program')\n",
        "\n",
        "    [node, declaration_list] = parser\n",
        "\n",
        "    node.insert_node(declaration_list)\n",
        "\n",
        "    syntax_tree = parser[0]\n",
        "    \n",
        "    pass\n",
        "\n",
        "def p_var(parser):\n",
        "    \"\"\"var : id\n",
        "           | id LBRACKETS expression RBRACKETS\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='var')\n",
        "\n",
        "    [node, id_node] = parser[:2]\n",
        "\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [_, expression] = parser[2:4]\n",
        "        node.insert_node_with_child(TreeNode(id='LBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "        node.insert_node(expression)\n",
        "        node.insert_node_with_child(TreeNode(id='RBRACKETS'), TreeNode(raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "\n",
        "# TODO: Estava faltando term. Verificar a montagem do nó.\n",
        "\n",
        "def p_term(parser):\n",
        "    \"\"\"term : term mulop factor\n",
        "            | factor\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='term')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [mulop] = parser[2:3]\n",
        "        node.insert_node(mulop)\n",
        "        [factor] = parser[3:4]\n",
        "        node.insert_node(factor)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_factor(parser):\n",
        "    \"\"\"factor : LPAREN expression RPAREN\n",
        "              | var\n",
        "              | call\n",
        "              | number\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='factor')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('LPAREN') == leaf:\n",
        "        [exp] = parser[2:3]\n",
        "\n",
        "        node.insert_node_with_child(TreeNode(id='LPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "        node.insert_node(exp)\n",
        "        node.insert_node_with_child(TreeNode(id='RPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    else:\n",
        "        node.insert_node(leaf)\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_call(parser):\n",
        "    \"\"\"call : id LPAREN args RPAREN\"\"\"\n",
        "    parser[0] = TreeNode(id='call')\n",
        "\n",
        "    [node, id_raw, _, args, _] = parser\n",
        "\n",
        "    id_node = TreeNode(id='ID')\n",
        "    id_node.insert_node(TreeNode(raw=id_raw))\n",
        "\n",
        "    node.insert_node(id_node)\n",
        "    node.insert_node_with_child(TreeNode(id='LPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(args)\n",
        "    node.insert_node_with_child(TreeNode(id='RPAREN'), TreeNode(raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    pass\n",
        "\n",
        "def p_id(parser):\n",
        "    \"\"\"id : ID\"\"\"\n",
        "    parser[0] = TreeNode(id='ID')\n",
        "    [node, id_raw] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=id_raw))\n",
        "    pass\n",
        "\n",
        "def p_number(parser):\n",
        "    \"\"\"number : NUMBER\"\"\"\n",
        "    parser[0] = TreeNode(id='NUMBER')\n",
        "    [node, number] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=number))\n",
        "    pass\n",
        "\n",
        "def p_args(parser):\n",
        "    \"\"\"args : arg-list\n",
        "            | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='args')\n",
        "    [node, leaf] = parser\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "    pass\n",
        "\n",
        "def p_arg_list(parser):\n",
        "    \"\"\"arg-list : arg-list COMMA expression\n",
        "                | expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='arg-list')\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "    if len(parser) > 2:\n",
        "        [_, exp] = parser[2:4]\n",
        "        node.insert_node_with_child(TreeNode(id='COMMA'), TreeNode(raw=TOKENS_SYMBOLS.get('COMMA')))\n",
        "        node.insert_node(exp)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_empty(parser):\n",
        "    \"\"\"empty :\"\"\"\n",
        "    parser[0] = TreeNode(id='EMPTY')\n",
        "    pass\n",
        "\n",
        "def p_error(parser):\n",
        "\n",
        "    if parser:\n",
        "        token = parser\n",
        "        print(\"Erro:[{line},{column}]: Erro próximo ao token '{token}'\".format(\n",
        "            line=token.lineno, column=token.lineno, token=token.value))\n",
        "    pass"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/grammar/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfKiXuDQlWz5"
      },
      "source": [
        "Conteúdo do `parser/__init__.py`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM4YQ4VLlF0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968d7a4e-71e3-478c-ff6e-d9668cf0189b"
      },
      "source": [
        "%%writefile parser/__init__.py\n",
        "import ply.yacc as yacc\n",
        "from lexer import tokens\n",
        "from .grammar import *\n",
        "\n",
        "# parser = yacc.yacc(start='program')\n",
        "parser = yacc.yacc(method=\"LALR\", optimize=True, start='program', debug=True,\n",
        "                   debuglog=log, write_tables=False, tabmodule='cmm_parser_tab')\n",
        " "
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting parser/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFXNEIehmzv_"
      },
      "source": [
        "Executando o código do `parser` utilizando o código principal do `cmmcompiler`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4_q5L1Nsq2p",
        "outputId": "c5f52f2f-62eb-4ba3-c5c4-5a2dbaf97402"
      },
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import utils\n",
        "from lexer import get_tokens\n",
        "from parser import parser\n",
        "from semantic import sema, Semantic\n",
        "from gencode import gencode, GenCode\n",
        "from tree import TreeNode\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    filename = \"cmmcompiler.log\",\n",
        "    encoding='utf-8',\n",
        "    level = logging.DEBUG,\n",
        "    filemode = \"w\",\n",
        "    format = \"%(filename)10s:%(lineno)4d:%(message)s\")\n",
        "log = logging.getLogger()\n",
        "\n",
        "syntax_tree = None\n",
        "reduced_syntax_tree = None\n",
        "\n",
        "def execute_lexical_analysis(source_input):\n",
        "    log.info(\"[lexer]: Executing Lexical Analysis.\")\n",
        "    for token in get_tokens(source_input):\n",
        "        print(token.type, token.value)\n",
        "    return\n",
        "\n",
        "def execute_syntax_analisys(source_input):\n",
        "    log.info(\"[parser]: Executing Syntax Analysis.\")\n",
        "    syntax_tree = parser.parse(source_input)\n",
        "    if syntax_tree != ():\n",
        "        print(\"Generating Syntax Tree Graph...\")\n",
        "        graph = utils.Graph(utils.args.file, 'Sintax Tree')\n",
        "        # program = parser.parse(source_input)\n",
        "        syntax_tree.render(graph)\n",
        "        graph.export()\n",
        "    return syntax_tree\n",
        "\n",
        "def execute_semantic_analisys(syntax_tree):\n",
        "    log.info(\"[sema]: Executing Semantic Analysis.\")\n",
        "    sema = Semantic(syntax_tree)\n",
        "    sema.check_semantic_rules()\n",
        "    return reduced_syntax_tree\n",
        "\n",
        "def execute_code_generation(reduced_syntax_tree):\n",
        "    log.info(\"[gencode]: Executing Code Generation.\")\n",
        "    gencode = GenCode(reduced_syntax_tree)\n",
        "    gencode.generate()\n",
        "    return\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \n",
        "  # __file__ = \"02-comp-analise-sintatica-cmmparser.ipynb\"\n",
        "\n",
        "  with open(utils.args.file) as file:\n",
        "      source_input = file.read()\n",
        "      if utils.args.lexer:\n",
        "          execute_lexical_analysis(source_input)    \n",
        "      pass\n",
        "\n",
        "      if utils.args.parser:\n",
        "          syntax_tree = execute_syntax_analisys(source_input) \n",
        "      pass\n",
        "        \n",
        "      if utils.args.semantic:\n",
        "          if syntax_tree != ():\n",
        "              reduced_syntax_tree = execute_semantic_analisys(syntax_tree)\n",
        "          else:\n",
        "              syntax_tree = execute_syntax_analisys(source_input)\n",
        "              reduced_syntax_tree = execute_semantic_analisys(syntax_tree)\n",
        "          pass\n",
        "      pass\n",
        "\n",
        "      if utils.args.gencode:\n",
        "          if reduced_syntax_tree != None:\n",
        "              execute_code_generation(reduced_syntax_tree)\n",
        "          else:\n",
        "              syntax_tree = execute_syntax_analisys(source_input)\n",
        "              if syntax_tree != ():\n",
        "                  reduced_syntax_tree = execute_semantic_analisys(syntax_tree)\n",
        "                  execute_code_generation(reduced_syntax_tree)\n",
        "              pass\n",
        "\n",
        "      pass\n",
        "        \n",
        "  pass\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6geznynhxI0t",
        "outputId": "a0d499d9-9206-445f-bf92-f77d4aee7a7b"
      },
      "source": [
        "! python main.py -p prog-001.cm"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating LALR tables\n",
            "WARNING: 1 shift/reduce conflict\n",
            "Generating Syntax Tree Graph...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "I4CO2u8148sm",
        "outputId": "11a50c18-f064-471d-fb05-29d9a1802736"
      },
      "source": [
        "import graphviz\n",
        "\n",
        "with open(\"graph.gv\") as f:\n",
        "    dot_graph = f.read()\n",
        "\n",
        "graphviz.Source(dot_graph)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f4d9361e090>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"1041pt\" height=\"476pt\"\n viewBox=\"0.00 0.00 1041.39 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-472 1037.3899,-472 1037.3899,4 -4,4\"/>\n<!-- 24 -->\n<g id=\"node1\" class=\"node\">\n<title>24</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.4446\" cy=\"-450\" rx=\"42.4939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"308.4446\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">program</text>\n</g>\n<!-- 23 -->\n<g id=\"node2\" class=\"node\">\n<title>23</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.4446\" cy=\"-378\" rx=\"64.9885\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"308.4446\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">declaration&#45;list</text>\n</g>\n<!-- 24&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>24&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M308.4446,-431.8314C308.4446,-424.131 308.4446,-414.9743 308.4446,-406.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.9447,-406.4132 308.4446,-396.4133 304.9447,-406.4133 311.9447,-406.4132\"/>\n</g>\n<!-- 22 -->\n<g id=\"node3\" class=\"node\">\n<title>22</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.4446\" cy=\"-306\" rx=\"51.1914\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"308.4446\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">declaration</text>\n</g>\n<!-- 23&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>23&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M308.4446,-359.8314C308.4446,-352.131 308.4446,-342.9743 308.4446,-334.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.9447,-334.4132 308.4446,-324.4133 304.9447,-334.4133 311.9447,-334.4132\"/>\n</g>\n<!-- 17 -->\n<g id=\"node4\" class=\"node\">\n<title>17</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"308.4446\" cy=\"-234\" rx=\"66.8882\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"308.4446\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">fun&#45;declaration</text>\n</g>\n<!-- 22&#45;&gt;17 -->\n<g id=\"edge21\" class=\"edge\">\n<title>22&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M308.4446,-287.8314C308.4446,-280.131 308.4446,-270.9743 308.4446,-262.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"311.9447,-262.4132 308.4446,-252.4133 304.9447,-262.4133 311.9447,-262.4132\"/>\n</g>\n<!-- 2 -->\n<g id=\"node5\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"60.4446\" cy=\"-162\" rx=\"60.3893\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"60.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">type&#45;specifier</text>\n</g>\n<!-- 17&#45;&gt;2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>17&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M262.6686,-220.7102C220.5108,-208.4708 157.964,-190.3121 113.6103,-177.4352\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.455,-174.036 103.8757,-174.609 112.5033,-180.7584 114.455,-174.036\"/>\n</g>\n<!-- 3 -->\n<g id=\"node8\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"165.4446\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"165.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ID</text>\n</g>\n<!-- 17&#45;&gt;3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>17&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M276.7083,-218.0209C252.7369,-205.9514 220.0221,-189.4796 196.2749,-177.5229\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.8393,-174.392 187.3335,-173.021 194.6913,-180.6443 197.8393,-174.392\"/>\n</g>\n<!-- 18 -->\n<g id=\"node10\" class=\"node\">\n<title>18</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"257.4446\" cy=\"-162\" rx=\"46.5926\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"257.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LPAREN</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge7\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M295.8379,-216.2022C289.7854,-207.6576 282.4179,-197.2564 275.7614,-187.859\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"278.5427,-185.7302 269.9064,-179.593 272.8305,-189.7764 278.5427,-185.7302\"/>\n</g>\n<!-- 7 -->\n<g id=\"node12\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"359.4446\" cy=\"-162\" rx=\"37.0935\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"359.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">params</text>\n</g>\n<!-- 17&#45;&gt;7 -->\n<g id=\"edge10\" class=\"edge\">\n<title>17&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M321.0514,-216.2022C327.1942,-207.5301 334.6916,-196.9455 341.4254,-187.4389\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"344.41,-189.2806 347.3341,-179.0972 338.6978,-185.2344 344.41,-189.2806\"/>\n</g>\n<!-- 20 -->\n<g id=\"node15\" class=\"node\">\n<title>20</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"461.4446\" cy=\"-162\" rx=\"47.3916\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"461.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RPAREN</text>\n</g>\n<!-- 17&#45;&gt;20 -->\n<g id=\"edge12\" class=\"edge\">\n<title>17&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M342.0211,-218.1993C365.7332,-207.0407 397.5801,-192.0539 422.4232,-180.363\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"424.0122,-183.4835 431.5701,-176.0586 421.0316,-177.1498 424.0122,-183.4835\"/>\n</g>\n<!-- 12 -->\n<g id=\"node17\" class=\"node\">\n<title>12</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"695.4446\" cy=\"-162\" rx=\"69.5877\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"695.4446\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">compound&#45;stmt</text>\n</g>\n<!-- 17&#45;&gt;12 -->\n<g id=\"edge20\" class=\"edge\">\n<title>17&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M363.8923,-223.6842C433.7569,-210.6861 553.7216,-188.3671 628.5868,-174.4387\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"629.6502,-177.801 638.8413,-172.5308 628.3698,-170.919 629.6502,-177.801\"/>\n</g>\n<!-- 0 -->\n<g id=\"node6\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"60.4446\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"60.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">INT</text>\n</g>\n<!-- 2&#45;&gt;0 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M60.4446,-143.8314C60.4446,-136.131 60.4446,-126.9743 60.4446,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.9447,-118.4132 60.4446,-108.4133 56.9447,-118.4133 63.9447,-118.4132\"/>\n</g>\n<!-- 1 -->\n<g id=\"node7\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"60.4446\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"60.4446\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">int</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M60.4446,-71.8314C60.4446,-64.131 60.4446,-54.9743 60.4446,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"63.9447,-46.4132 60.4446,-36.4133 56.9447,-46.4133 63.9447,-46.4132\"/>\n</g>\n<!-- 4 -->\n<g id=\"node9\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"165.4446\" cy=\"-90\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"165.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">main</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M165.4446,-143.8314C165.4446,-136.131 165.4446,-126.9743 165.4446,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"168.9447,-118.4132 165.4446,-108.4133 161.9447,-118.4133 168.9447,-118.4132\"/>\n</g>\n<!-- 19 -->\n<g id=\"node11\" class=\"node\">\n<title>19</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"257.4446\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"257.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge6\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M257.4446,-143.8314C257.4446,-136.131 257.4446,-126.9743 257.4446,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.9447,-118.4132 257.4446,-108.4133 253.9447,-118.4133 260.9447,-118.4132\"/>\n</g>\n<!-- 5 -->\n<g id=\"node13\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"359.4446\" cy=\"-90\" rx=\"34.394\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"359.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">VOID</text>\n</g>\n<!-- 7&#45;&gt;5 -->\n<g id=\"edge9\" class=\"edge\">\n<title>7&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M359.4446,-143.8314C359.4446,-136.131 359.4446,-126.9743 359.4446,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"362.9447,-118.4132 359.4446,-108.4133 355.9447,-118.4133 362.9447,-118.4132\"/>\n</g>\n<!-- 6 -->\n<g id=\"node14\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"359.4446\" cy=\"-18\" rx=\"27.8951\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"359.4446\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">void</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M359.4446,-71.8314C359.4446,-64.131 359.4446,-54.9743 359.4446,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"362.9447,-46.4132 359.4446,-36.4133 355.9447,-46.4133 362.9447,-46.4132\"/>\n</g>\n<!-- 21 -->\n<g id=\"node16\" class=\"node\">\n<title>21</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"449.4446\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"449.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">)</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge11\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M458.4165,-143.8314C457.1134,-136.0125 455.56,-126.6923 454.115,-118.0221\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"457.5267,-117.2019 452.4302,-107.9134 450.6219,-118.3528 457.5267,-117.2019\"/>\n</g>\n<!-- 13 -->\n<g id=\"node18\" class=\"node\">\n<title>13</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"548.4446\" cy=\"-90\" rx=\"53.8905\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"548.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LBRACES</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M662.8206,-146.0209C640.7175,-135.1949 611.3831,-120.827 587.9563,-109.3527\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"589.4903,-106.2067 578.9701,-104.9512 586.4111,-112.4932 589.4903,-106.2067\"/>\n</g>\n<!-- 9 -->\n<g id=\"node20\" class=\"node\">\n<title>9</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"695.4446\" cy=\"-90\" rx=\"75.2868\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"695.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">local&#45;declarations</text>\n</g>\n<!-- 12&#45;&gt;9 -->\n<g id=\"edge16\" class=\"edge\">\n<title>12&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M695.4446,-143.8314C695.4446,-136.131 695.4446,-126.9743 695.4446,-118.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"698.9447,-118.4132 695.4446,-108.4133 691.9447,-118.4133 698.9447,-118.4132\"/>\n</g>\n<!-- 11 -->\n<g id=\"node22\" class=\"node\">\n<title>11</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"848.4446\" cy=\"-90\" rx=\"59.2899\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"848.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">statement&#45;list</text>\n</g>\n<!-- 12&#45;&gt;11 -->\n<g id=\"edge17\" class=\"edge\">\n<title>12&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M729.0211,-146.1993C752.0312,-135.371 782.7015,-120.9379 807.1987,-109.4098\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"808.6985,-112.5723 816.2564,-105.1474 805.7179,-106.2386 808.6985,-112.5723\"/>\n</g>\n<!-- 15 -->\n<g id=\"node23\" class=\"node\">\n<title>15</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"979.4446\" cy=\"-90\" rx=\"53.8905\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"979.4446\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RBRACES</text>\n</g>\n<!-- 12&#45;&gt;15 -->\n<g id=\"edge19\" class=\"edge\">\n<title>12&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M747.3862,-149.9072C792.2631,-139.3162 858.7933,-123.2732 916.4446,-108 920.465,-106.9349 924.622,-105.8069 928.7947,-104.6557\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"929.8116,-108.0057 938.5024,-101.9459 927.9296,-101.2634 929.8116,-108.0057\"/>\n</g>\n<!-- 14 -->\n<g id=\"node19\" class=\"node\">\n<title>14</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"548.4446\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"548.4446\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">{</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge13\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M548.4446,-71.8314C548.4446,-64.131 548.4446,-54.9743 548.4446,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"551.9447,-46.4132 548.4446,-36.4133 544.9447,-46.4133 551.9447,-46.4132\"/>\n</g>\n<!-- 8 -->\n<g id=\"node21\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"695.4446\" cy=\"-18\" rx=\"42.7926\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"695.4446\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">EMPTY</text>\n</g>\n<!-- 9&#45;&gt;8 -->\n<g id=\"edge15\" class=\"edge\">\n<title>9&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M695.4446,-71.8314C695.4446,-64.131 695.4446,-54.9743 695.4446,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"698.9447,-46.4132 695.4446,-36.4133 691.9447,-46.4133 698.9447,-46.4132\"/>\n</g>\n<!-- 16 -->\n<g id=\"node24\" class=\"node\">\n<title>16</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"979.4446\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"979.4446\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">}</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge18\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M979.4446,-71.8314C979.4446,-64.131 979.4446,-54.9743 979.4446,-46.4166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"982.9447,-46.4132 979.4446,-36.4133 975.9447,-46.4133 982.9447,-46.4132\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJROew1nd_bu"
      },
      "source": [
        "## Trabalho de Implementação\n",
        "\n",
        "Foram feitas algumas alterações para incluir o suporte ao tipo `float` e arranjos bidimensionais (matrizes).\n",
        "\n",
        "```.ebnf\n",
        "type-specifier ::= int | float | void\n",
        "var-declaration ::= type-specifier ID ; | type-specifier ID [ NUM ] ; | type-specifier ID [ NUM ] [ NUM ] ;\n",
        "param ::= type-specifier ID | type-specifier ID [ ] | type-specifier ID [ ] [ ]\n",
        "\n",
        "```"
      ]
    }
  ]
}