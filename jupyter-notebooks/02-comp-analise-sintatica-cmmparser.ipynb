{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-comp-analise-sintatica-cmmparser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rogerioag/rea-comp04-compiladores/blob/main/jupyter-notebooks/02-comp-analise-sintatica-cmmparser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQtiaYOH3xV9"
      },
      "source": [
        "# Análise Sintática"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9TX9STdBDfD",
        "outputId": "8e6ebbec-8e0b-4dbc-c1d6-4a0626e94682"
      },
      "source": [
        "!pip install ply\n",
        "!pip install anytree\n",
        "!pip install graphviz\n",
        "!pip install llvmlite\n",
        "!jupyter nbextension install https://rawgit.com/jfbercher/small_nbextensions/master/highlighter.zip  --user\n",
        "!jupyter nbextension enable highlighter/highlighter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ply\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▋                         | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 30kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: ply\n",
            "Successfully installed ply-3.11\n",
            "Collecting anytree\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/65/be23d8c3ecd68d40541d49812cd94ed0f3ee37eb88669ca15df0e43daed1/anytree-2.8.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from anytree) (1.15.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.8.0\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Downloading: https://rawgit.com/jfbercher/small_nbextensions/master/highlighter.zip -> /tmp/tmpAIKit7/highlighter.zip\n",
            "Extracting: /tmp/tmpAIKit7/highlighter.zip -> /root/.local/share/jupyter/nbextensions\n",
            "Enabling notebook extension highlighter/highlighter...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3CciW1-tIp1",
        "outputId": "ed9009fe-9b0f-497f-8ecb-033a2f63f132"
      },
      "source": [
        "! git clone https://github.com/rogerioag/rea-comp04-compiladores.git\n",
        "! cp -R rea-comp04-compiladores/cmmcompiler/* .\n",
        "! cp -R rea-comp04-compiladores/cmmcompiler/tests/* .\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rea-comp04-compiladores'...\n",
            "remote: Enumerating objects: 251, done.\u001b[K\n",
            "remote: Counting objects: 100% (251/251), done.\u001b[K\n",
            "remote: Compressing objects: 100% (211/211), done.\u001b[K\n",
            "remote: Total 251 (delta 122), reused 127 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (251/251), 556.20 KiB | 6.70 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1X7BKd1lF0A"
      },
      "source": [
        "from sys import argv, exit\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "     level = logging.DEBUG,\n",
        "     filename = \"log.txt\",\n",
        "     filemode = \"w\",\n",
        "     format = \"%(filename)10s:%(lineno)4d:%(message)s\"\n",
        ")\n",
        "log = logging.getLogger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0dCv_649wA"
      },
      "source": [
        "import ply.yacc as yacc\n",
        "from lexer import tokens\n",
        "import re as regex\n",
        "\n",
        "from lexer import TOKENS_SYMBOLS\n",
        "from tree import TreeNode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_rJYh575BMi"
      },
      "source": [
        "# from .declarations import *\n",
        "\n",
        "def p_declaration_list(parser):\n",
        "    \"\"\"declaration-list : declaration-list declaration\n",
        "                        | declaration\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='DECLARATION_LIST')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "        [dec] = parser[2:3]\n",
        "        node.insert_node(dec)\n",
        "        pass\n",
        "    else:\n",
        "        node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_declaration(parser):\n",
        "    \"\"\"declaration : var-declaration\n",
        "                   | fun-declaration\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='DECLARATION')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_var_declaration(parser):\n",
        "    \"\"\"var-declaration : type-specifier id SEMICOLON\n",
        "                       | type-specifier id LBRACKETS number RBRACKETS\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='VAR_DECLARATION')\n",
        "\n",
        "    [node, type_spec, id_node, symbol] = parser[:4]\n",
        "\n",
        "    node.insert_node(type_spec)\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == symbol:\n",
        "        node.insert_node(TreeNode(id='SEMICOLON', raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "        pass\n",
        "    elif TOKENS_SYMBOLS.get('LBRACKETS') == symbol:\n",
        "        node.insert_node(TreeNode(id='LBRACKETS', raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "        \n",
        "        [number] = parser[4:5]\n",
        "        node.insert_node(number)\n",
        "\n",
        "        node.insert_node(TreeNode(id='RBRACKETS', raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_fun_declaration(parser):\n",
        "    \"\"\"fun-declaration : type-specifier id LPAREN params RPAREN compound-stmt\"\"\"\n",
        "    parser[0] = TreeNode(id='FUN_DECLARATION')\n",
        "\n",
        "    [node, type_spec, id_node, _, params, _, compound] = parser\n",
        "\n",
        "    node.insert_node(type_spec)\n",
        "    node.insert_node(id_node)\n",
        "    node.insert_node(TreeNode(id='LPAREN', raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(params)\n",
        "    node.insert_node(TreeNode(id='RPAREN', raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(compound)\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_local_declarations(parser):\n",
        "    \"\"\"local-declarations : local-declarations var-declaration\n",
        "                          | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='LOCAL_DECLARATIONS')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [var] = parser[2:3]\n",
        "        node.insert_node(var)\n",
        "        pass\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP2-jB4f5EdT"
      },
      "source": [
        "# from .expressions import *\n",
        "\n",
        "def p_expressions(parser):\n",
        "    \"\"\"expression : var ATTRIBUTION expression\n",
        "                  | simple-expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='EXPRESSION')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    if len(parser) > 2:\n",
        "        [_, exp] = parser[2:4]\n",
        "        node.insert_node(TreeNode(id='ATTRIBUTION', raw=TOKENS_SYMBOLS.get('ATTRIBUTION')))\n",
        "        node.insert_node(exp)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_simple(parser):\n",
        "    \"\"\"simple-expression : additive-expression relop additive-expression\n",
        "                         | additive-expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='SIMPLE_EXPRESSION')\n",
        "\n",
        "    [node, add] = parser[:2]\n",
        "\n",
        "    node.insert_node(add)\n",
        "    if len(parser) > 2:\n",
        "        [relop, addi] = parser[2:4]\n",
        "        node.insert_node(relop)\n",
        "        node.insert_node(addi)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_additive(parser):\n",
        "    \"\"\"additive-expression : additive-expression addop term\n",
        "                           | term\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='ADDITIVE_EXPRESSION')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    if len(parser) > 2:\n",
        "        [addop, term] = parser[2:4]\n",
        "        node.insert_node(addop)\n",
        "        node.insert_node(term)\n",
        "        pass\n",
        "    pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbuPEMzy5Gxy"
      },
      "source": [
        "# from .operations import *\n",
        "\n",
        "def get_token_by_raw(raw):\n",
        "    \n",
        "    for (token, value) in TOKENS_SYMBOLS.items():\n",
        "        if value == raw:\n",
        "            return token\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def p_relational(parser):\n",
        "    \"\"\"relop : LESS_EQUAL\n",
        "             | LESS\n",
        "             | GREATER\n",
        "             | GREATER_EQUAL\n",
        "             | EQUALS\n",
        "             | DIFFERENT\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw), raw=raw)\n",
        "    pass\n",
        "\n",
        "def p_addition(parser):\n",
        "    \"\"\"addop : PLUS\n",
        "             | MINUS\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw), raw=raw)\n",
        "    pass\n",
        "\n",
        "def p_multiplication(parser):\n",
        "    \"\"\"mulop : TIMES\n",
        "             | DIVIDE\n",
        "    \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id=get_token_by_raw(raw), raw=raw)\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEOieoD5Jao"
      },
      "source": [
        "# from .params import *\n",
        "def p_params(parser):\n",
        "    \"\"\"params : param-list\n",
        "              | void\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='PARAMS')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_param_list(parser):\n",
        "    \"\"\"param-list : param-list COMMA param\n",
        "                  | param\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='PARAM_LIST')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "\n",
        "        [_, param] = parser[2:4]\n",
        "        node.insert_node(TreeNode(id='COMMA', raw=TOKENS_SYMBOLS.get('COMMA')))\n",
        "        node.insert_node(param)\n",
        "    else:\n",
        "        node.insert_node(subtree)\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_param(parser):\n",
        "    \"\"\"param : type-specifier id\n",
        "             | type-specifier id LBRACKETS RBRACKETS\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='PARAM')\n",
        "\n",
        "    [node, subtree, id_node] = parser[:3]\n",
        "    node.insert_node(subtree)\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "    if len(parser) > 3:\n",
        "        node.insert_node(TreeNode(id='LBRACKETS', raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "        node.insert_node(TreeNode(id='RBRACKETS', raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "        pass\n",
        "\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aI_VH_25Ln8"
      },
      "source": [
        "# from .types import *\n",
        "\n",
        "def p_type_specifier(parser):\n",
        "    \"\"\"type-specifier : int\n",
        "                      | void\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='TYPE_SPECIFIER')\n",
        "    [node, type_node] = parser\n",
        "\n",
        "    node.insert_node(type_node)\n",
        "    pass\n",
        "\n",
        "def p_void(parser):\n",
        "    \"\"\"void : VOID \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id='VOID', raw=raw)\n",
        "    pass\n",
        "\n",
        "def p_int(parser):\n",
        "    \"\"\"int : INT \"\"\"\n",
        "    [_, raw] = parser\n",
        "    parser[0] = TreeNode(id='INT', raw=raw)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5PFMFeT5PCt"
      },
      "source": [
        "# from .statements import *\n",
        "\n",
        "def p_statement_list(parser):\n",
        "    \"\"\"statement-list : statement-list statement\n",
        "                      | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='STATEMENT_LIST')\n",
        "\n",
        "    [node, subtree] = parser[:2]\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_nodes(subtree.nodes())\n",
        "        [stmt] = parser[2:3]\n",
        "        node.insert_node(stmt)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_statement(parser):\n",
        "    \"\"\"statement : expression-stmt\n",
        "                 | compound-stmt\n",
        "                 | selection-stmt\n",
        "                 | iteration-stmt\n",
        "                 | return-stmt\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='STATEMENT')\n",
        "\n",
        "    [node, subtree] = parser\n",
        "\n",
        "    node.insert_node(subtree)\n",
        "    pass\n",
        "\n",
        "def p_expression(parser):\n",
        "    \"\"\"expression-stmt : expression SEMICOLON\n",
        "                       | SEMICOLON\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='EXPRESSION_STMT')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == leaf:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=leaf)\n",
        "\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        node.insert_node(TreeNode(id='SEMICOLON', raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_compound(parser):\n",
        "    \"\"\"compound-stmt : LBRACES local-declarations statement-list RBRACES\"\"\"\n",
        "    parser[0] = TreeNode(id='COMPOUND_STMT')\n",
        "\n",
        "    [node, _, local_decl, stmt_list, _] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(id='LBRACES', raw=TOKENS_SYMBOLS.get('LBRACES')))\n",
        "    node.insert_node(local_decl)\n",
        "    node.insert_node(stmt_list)\n",
        "    node.insert_node(TreeNode(id='RBRACES', raw=TOKENS_SYMBOLS.get('RBRACES')))\n",
        "    \n",
        "    pass\n",
        "\n",
        "def p_selection(parser):\n",
        "    \"\"\"selection-stmt : IF LPAREN expression RPAREN statement\n",
        "                      | IF LPAREN expression RPAREN statement ELSE statement\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='SELECTION_STMT')\n",
        "\n",
        "    [node, _, _, exp, _, stmt] = parser[:6]\n",
        "\n",
        "    node.insert_node(TreeNode(id='IF', raw=TOKENS_SYMBOLS.get('IF')))\n",
        "    node.insert_node(TreeNode(id='LPAREN', raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(exp)\n",
        "    node.insert_node(TreeNode(id='RPAREN', raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(stmt)\n",
        "\n",
        "    if len(parser) > 6:\n",
        "        [_, stmt] = parser[6:8]\n",
        "        node.insert_node(TreeNode(id='ELSE', raw=TOKENS_SYMBOLS.get('ELSE')))\n",
        "        node.insert_node(stmt)\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_iteration(parser):\n",
        "    \"\"\"iteration-stmt : WHILE LPAREN expression RPAREN statement\"\"\"\n",
        "    parser[0] = TreeNode(id='ITERATION_STMT')\n",
        "\n",
        "    [node, _, _, exp, _, stmt] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(id='WHILE', raw=TOKENS_SYMBOLS.get('WHILE')))\n",
        "    node.insert_node(TreeNode(id='LPAREN', raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(exp)\n",
        "    node.insert_node(TreeNode(id='RPAREN', raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    node.insert_node(stmt)\n",
        "    pass\n",
        "\n",
        "def p_return(parser):\n",
        "    \"\"\"return-stmt : RETURN SEMICOLON\n",
        "                   | RETURN expression SEMICOLON\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='RETURN_STMT')\n",
        "\n",
        "    [node, _, leaf] = parser[:3]\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('SEMICOLON') == leaf:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=leaf)\n",
        "\n",
        "    node.insert_node(TreeNode(id='RETURN', raw=TOKENS_SYMBOLS.get('RETURN')))\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 3:\n",
        "        leaf = TreeNode(id='SEMICOLON', raw=TOKENS_SYMBOLS.get('SEMICOLON'))\n",
        "\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQgiplz5lF0M"
      },
      "source": [
        "\n",
        "def p_program(parser):\n",
        "    \"\"\"program : declaration-list\"\"\"\n",
        "    parser[0] = TreeNode(id='PROGRAM')\n",
        "\n",
        "    [node, declaration_list] = parser\n",
        "\n",
        "    node.insert_node(declaration_list)\n",
        "    pass\n",
        "\n",
        "def p_var(parser):\n",
        "    \"\"\"var : id\n",
        "           | id LBRACKETS expression RBRACKETS\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='VAR')\n",
        "\n",
        "    [node, id_node] = parser[:2]\n",
        "\n",
        "    node.insert_node(id_node)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [_, expression] = parser[2:4]\n",
        "        node.insert_node(TreeNode(id='LBRACKETS', raw=TOKENS_SYMBOLS.get('LBRACKETS')))\n",
        "        node.insert_node(expression)\n",
        "        node.insert_node(TreeNode(id='RBRACKETS', raw=TOKENS_SYMBOLS.get('RBRACKETS')))\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_term(parser):\n",
        "    \"\"\"term : mulop factor\n",
        "            | factor\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='TERM')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "    node.insert_node(leaf)\n",
        "\n",
        "    if len(parser) > 2:\n",
        "        [factor] = parser[2:3]\n",
        "        node.insert_node(factor)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_factor(parser):\n",
        "    \"\"\"factor : LPAREN expression RPAREN\n",
        "              | var\n",
        "              | call\n",
        "              | number\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='FACTOR')\n",
        "\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "    if TOKENS_SYMBOLS.get('LPAREN') == leaf:\n",
        "        [exp] = parser[2:3]\n",
        "\n",
        "        node.insert_node(TreeNode(id='LPAREN', raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "        node.insert_node(exp)\n",
        "        node.insert_node(TreeNode(id='RPAREN', raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    else:\n",
        "        node.insert_node(leaf)\n",
        "        pass\n",
        "\n",
        "    pass\n",
        "\n",
        "def p_call(parser):\n",
        "    \"\"\"call : id LPAREN args RPAREN\"\"\"\n",
        "    parser[0] = TreeNode(id='CALL')\n",
        "\n",
        "    [node, id_raw, _, args] = parser\n",
        "\n",
        "    id_node = TreeNode(id='ID')\n",
        "    id_node.insert_node(TreeNode(raw=id_raw))\n",
        "\n",
        "    node.insert_node(id_node)\n",
        "    node.insert_node(TreeNode(id='LPAREN', raw=TOKENS_SYMBOLS.get('LPAREN')))\n",
        "    node.insert_node(args)\n",
        "    node.insert_node(TreeNode(id='RPAREN', raw=TOKENS_SYMBOLS.get('RPAREN')))\n",
        "    pass\n",
        "\n",
        "def p_id(parser):\n",
        "    \"\"\"id : ID\"\"\"\n",
        "    parser[0] = TreeNode(id='ID')\n",
        "    [node, id_raw] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=id_raw))\n",
        "    pass\n",
        "\n",
        "def p_number(parser):\n",
        "    \"\"\"number : NUMBER\"\"\"\n",
        "    parser[0] = TreeNode(id='NUMBER')\n",
        "    [node, number] = parser\n",
        "\n",
        "    node.insert_node(TreeNode(raw=number))\n",
        "    pass\n",
        "\n",
        "def p_args(parser):\n",
        "    \"\"\"args : arg-list\n",
        "            | empty\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='ARGS')\n",
        "    [node, leaf] = parser\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "    pass\n",
        "\n",
        "def p_arg_list(parser):\n",
        "    \"\"\"arg-list : arg-list SEMICOLON expression\n",
        "                | expression\n",
        "    \"\"\"\n",
        "    parser[0] = TreeNode(id='ARG_LIST')\n",
        "    [node, leaf] = parser[:2]\n",
        "\n",
        "    node.insert_node(leaf)\n",
        "    if len(parser) > 2:\n",
        "        [_, exp] = parser[2:4]\n",
        "        node.insert_node(TreeNode(id='SEMICOLON', raw=TOKENS_SYMBOLS.get('SEMICOLON')))\n",
        "        node.insert_node(exp)\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "def p_empty(parser):\n",
        "    \"\"\"empty :\"\"\"\n",
        "    parser[0] = TreeNode(id='EMPTY')\n",
        "    pass\n",
        "\n",
        "def p_error(parser):\n",
        "\n",
        "    print(parser)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sghturgTpA-V"
      },
      "source": [
        "# Programa principal.\n",
        "def main():\n",
        "    argv[1] = 'prog-002.cm'\n",
        "    aux = argv[1].split('.')\n",
        "    if aux[-1] != 'cm':\n",
        "      raise IOError(\"Not a .cm file!\")\n",
        "    data = open(argv[1])\n",
        "\n",
        "    source_file = data.read()\n",
        "    parser.parse(source_file)\n",
        "\n",
        "    print(\"Parsing...\", argv[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM4YQ4VLlF0g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "90e51cde-32ef-4550-94f8-a606b508ab45"
      },
      "source": [
        "# Build the parser.\n",
        "__file__ = \"02-comp-analise-sintatica-cmmparser.ipynb\"\n",
        "\n",
        "parser = yacc.yacc(method=\"LALR\", optimize=True, start='program', debug=True, debuglog=log, write_tables=False, tabmodule='cmm_parser_tab')\n",
        "# parser = yacc.yacc(start='program')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LexToken(RBRACES,'}',68,188)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Generating LALR tables\n",
            "WARNING: 1 shift/reduce conflict\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m02-comp-analise-sintatica-cmmparser.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m02-comp-analise-sintatica-cmmparser.ipynb\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msource_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Parsing...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ply/yacc.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, input, lexer, debug, tracking, tokenfunc)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseopt_notrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ply/yacc.py\u001b[0m in \u001b[0;36mparseopt_notrack\u001b[0;34m(self, input, lexer, debug, tracking, tokenfunc)\u001b[0m\n\u001b[1;32m   1118\u001b[0m                             \u001b[0;32mdel\u001b[0m \u001b[0msymstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m                             \u001b[0;32mdel\u001b[0m \u001b[0mstatestack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                             \u001b[0msymstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m02-comp-analise-sintatica-cmmparser.ipynb\u001b[0m in \u001b[0;36mp_call\u001b[0;34m(parser)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CALL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mid_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTreeNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6geznynhxI0t",
        "outputId": "176cdd48-51d0-4638-ca45-6a0054041681"
      },
      "source": [
        "! python main.py -p prog-002.cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LexToken(RBRACES,'}',2,188)\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 17, in <module>\n",
            "    program = parser.parse(as_str)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ply/yacc.py\", line 333, in parse\n",
            "    return self.parseopt_notrack(input, lexer, debug, tracking, tokenfunc)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ply/yacc.py\", line 1120, in parseopt_notrack\n",
            "    p.callable(pslice)\n",
            "  File \"/content/parser/grammar/__init__.py\", line 82, in p_call\n",
            "    [node, id_raw, _, args] = parser\n",
            "ValueError: too many values to unpack (expected 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}